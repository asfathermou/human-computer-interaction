# 多模态生理信号情感识别报告

标签： 课程作业

---

 - 课题背景
 - 主要参考文献和方法阐述
 - 主要工作
 - 问题和总结

---
 
## 课题背景
### 1.目标
本任务的主要目标是对在提取了交互者的生理信号下，对交互做出情感类的判别，所以这里的情感识别主要指的还是分类问题。本任务还是一个比较具有实时性的任务，主要是仅仅基于1秒的信号进行分类。
### 2.数据集
本任务提供了两个数据集：DEAP(http://www.eecs.qmul.ac.uk/mmv/datasets/deap/readme.html)和SEED(http://bcmi.sjtu.edu.cn/home/seed/download.html)，下面分别对这两个数据集做简要描述：

 1. DEAP:
DEAP数据集是基于32个实验对象随机观看了40个1分钟左右的音乐视频，记录了实验对象的生理信号，并且给出了三个方面的情感评价，分别是:Valence(效价)、Arousal(唤醒度)、Dominace(支配度?)，分别用1~9的整数表示。记录的生理信号经过预处理(下采样合并通道等方式)有40个通道，其中前32个通道是脑电EEG信号，33、34通道分别是眼动EOG信号，剩下的是其他生理信号(本作业没有采用)。
DEAP数据集所产生的分类目标是3个二分类问题。

 2. SEED: 
SEED数据集的实验对象是15个人，每个人观看了24个视频并记录生理信号，每个视频(约为4分钟)具有一个持续单一的情绪，用这个情绪来作为分类的Gound truth。总共有4个类别的情绪：中立、悲伤、害怕以及高兴。记录的生理信号分别是62个通道的EEG信号+前额眼电信号。在SEED识别中，本实验仅仅用了EEG信号，原因是对于经过预处理的眼电信号，并没有找到合适的方法加入网络。
SEED数据集的分类目标是1个四分类问题。

可以看出SEED数据集的分类目标较DEAP数据集的分类目标难一些。

---

## 主要参考文献和方法阐述
### EEG信号特征提取：
我们阅读的文章范畴主要是利用深度学习来解决识别问题，利用深度网络来解决这个问题主要的原因在于卷积神经网络的特征提取能力。由于处理的信号是既又空间域信息又有时间域信息，所以网络的构建一般是将空间域和时间域提取的信息进行融合，主要网络结构大致如下：

 1. 2dCNN并联1dLSTM：利用卷积网络来提取空间信息同时利用LSTM网络来提取时域信息，最后将特征进行融合进而做分类。
 2. 2dCNN串联1dLSTM：利用卷积网络逐帧提取空间域信息得到特征序列，并将特征序列利用LSTM进行特征提取。
 3. 3dCNN：将时域信息也采用CNN做提取。
 我们最后选择2dCNN并联1dLSTM作为基本模型，并基于它进行了初步实验。
参考文章：
1.https://ieeexplore.ieee.org/document/7822545/
2.http://arxiv.org/abs/1708.06578
3.https://arxiv.org/abs/1704.08619
### 多模态特征融合：
 依据文章(https://dl.acm.org/citation.cfm?id=2832411)里的结论，即眼动信号和EEG信号成某种程度上的互补关系，我们的多模态实验主要基于的是眼动数据EOG。而多模态融合思路主要采用了特征层的融合，将EEG和EOG分别提取特征后在某一层进行concatenation。

---

## 主要工作

我们的主要工作如下：
 - DEAP和SEED数据预处理
 - 实验一：验证模型结果
 - 实验二：模型改进-利用分离卷积提取时域信息
 - 实验三：模型改进-利用Attention提取时域信息
 - 实验四：模型探索-探索3个模型的泛化能力
 
### 数据预处理：
数据预处理的主要工作在于将EEG信号转为二维矩阵形式从而用2dCNN做特征提取、对EEG的basemean处理(文章中有提到，仅限于DEAP)、对DEAP和SEED的差异处理以及对眼动数据的预处理。
##### 1.EEG：$1D\Rightarrow2D$
将EEG(一维信号)转化为二维信号是一个目前比较主流的做法，这个做法的原因在于采取EEG信号的传感器是分布在测试对象的大脑上的，可以直觉的认为大脑相同区块的EEG信号具有相当的关联性，而如果直接处理一维EEG，就相当于没有给网络加入这样一个关联性先验。这会迫使网络自己去找邻域相关性，结果不会太好。利用二维矩阵的表达(按照传感器的位置排列)会使得网络能得到这种邻域相关性。
由于DEAP和SEED对EEG信号传感器布置都采用的是标准的$10-20$系统，所以根据论文中的方法，设计了一个$9\times9$的矩阵来容纳所有的传感器(这个矩阵是比较稀疏的，特别是对于只采用了32个通道脑电信号的DEAP数据集，不知道这种稀疏性会不会影响特征提取的结果)。具体的脑电图和二维矩阵示例(DEAP为例)如下：
<p>
<img src="./1.png" width="40%" height="30%" />
<img src="./2.png" width="50%" height="30%" />
</p>


##### 2.DEAP与SEED数据集差异
差异主要在，DEAP数据集的经过采样后的时间域长度是一致的，并且DEAP数据集提前对每个测试对象录了一个3秒的没有刺激EEG信号，在实际处理中，可以利用BaseMean的方法对剩余EEG信号做去噪，这会使得准确率提升。然而上述数据优点在SEED中都没有，这也造成了预处理的差异。

##### 3.对眼动数据的预处理
我们多模态只是在DEAP数据集上进行了实验，但是DEAP上的眼动数据价值并不大，进行预处理的时候也仅仅是按照128帧进行分块。

### 验证模型结果
为了对比两个数据集上的结果，在DEAP上我们没有采用论文中的BaseMean方法来去除EEG噪音，得到的部分结果如下：
<p>
DEAP结果：
<img src="./4.png" width="100%" height="30%" />
SEED结果：
<img src="./5.png" width="100%" height="20%" />
</p>
可以看出，实验在SEED上结果并不好，我们对结果进行了一定分析，推测可能是四分类使得问题变得比二分类复杂了，从而结果自然下降了。(初步结论)

### 实验二-利用分离卷积提取时域信息
在利用keras复刻论文中的网络时，利用了分离卷积的方法来处理时域信息，即，将128帧的时间轴视为通道(channel)，做分通道的卷积(采用固定大小的相同个数的卷积核在不同通道(帧)上做卷积)，进而再时间域上进行融合。
用分离卷积来代替原始的CNN(直接将2d信息提取完之后做concatenation)取得了比原来更好的效果。和论文中一样，我们对单个人的样本做了验证，epoch设置为20，每个epoch设置了15个batch，得到的部分结果如下：
<p>
<img src="./6.jpg" width="40%" height="40%" />
<img src="./7.jpg" width="40%" height="40%" />
</p>
可以看到这个结果是非常好的，仅仅6个epochs就达到收敛到96%(比原文做的实验结果要高)，这个结果是有一定问题的，后面会提到。
关于分离卷积，可以具体参照文章:https://arxiv.org/abs/1608.04337v1

### 实验三-利用注意力机制来提取时域信息
由于任务目标的实时性，即对1秒(DEAP数据集的128帧)做情感分类，所以时域信息的密度非常高。受到这个想法的启发，我们试着将注意力机制用来提取时域信息。之所以用注意力机制的原因(或者说注意力比LSTM网络更有优势的地方)在于，LSTM网络本质上仍然是序列识别，即要受限于序列的长度限制，对于相隔步长比较长的关系提取能力不强(即使LSTM已经在RNN的基础上加入了长时间记忆力)。而注意力机制，本质上就是去寻找全局的关系，具体应用到时间轴上，完全不受限制于两帧图像间的长度限制，非常适合做短时间任务，因为短时间任务往往各个帧都高度相关。
这里我们采取的是注意力表征(即注意力网络)作为时域特征提取，网络架构是先用CNN网络提取空间域的高层语义表征，后根据这些特征逐通道(总共13个通道)的加入attention网络，做时域特征提取。具体网络的计算步骤不在此详述，可以参照文章：https://arxiv.org/abs/1706.03762
具体在DEAP上的实验结果如下：
<p>
<img src="./8.jpg" width="40%" height="40%" />
<img src="./9.jpg" width="40%" height="40%" />
</p>
可以看出结果也相当不错，不过，和上面一样，这个结果仍然是有一定问题的。

### 实验四-探索3个模型的泛化能力
对于这个任务，在实际应用场景中，往往是希望能够利用一个训练好的模型去识别一个陌生人的情绪，所以这就对模型的泛化性能提出了很高的要求。我们也分别对原始模型、分离卷积模型和注意力模型的泛化性能进行了一定程度的探索。泛化能力主要是在训练集和测试集的划分上，我们先试验了3个目标作为训练集另一个目标作为测试集，测试结果三个模型都集中在测试准确率在50%-60%，而训练集已经到达了95%以上，明显可以说明模型过拟合了。但是，在加入了常用的正则化方法之后(Dropout层、参数的二范正则)，效果的提升并不特别明显。结果如下：
<p>
<img src="./10.jpg" width="40%" height="40%" />
<img src="./11.jpg" width="40%" height="40%" />
</p>
我们又试验了一个人作为测试集，一个人作为测试集，结果同样不好，如下：
<p>
<img src="./13.jpg" width="40%" height="40%" />
<img src="./12.jpg" width="40%" height="40%" />
</p>
后来我们发现，前面的良好结果是建立在分训练集和测试集之前进行shuffle的结果，这就导致了同一个人观看的40个视频的数据被打乱了，即训练样本的多样性增加，如果我们假设同一个人观看一个视频的EEG信号近似，那么这种做法相当于让模型"见了"很多测试集中的样本的紧邻样本。这也就间接说明了模型对同一个测试样本的泛化能力都是很有限的，后来进行的原始模型试验也证明了这个结论，在事前不对数据集进行shuffle的情况下，预测准确率也仅仅维持在50%左右，明显过拟合(即使加入了BaseMean预处理)。

所以，我们初步的得出结论，目前的模型的泛化性能实在有限，而仅仅用dropout等正则化技巧并不能弥补这种过拟合现象。我们认为解决方案仍然在给网络加入先验信息这个步骤上，这也是现在深度学习能在不同场景之中能得到更好效果的一个办法。

## 问题和总结
这个任务目前来看还没有达到实际应用的程度，还需要进一步研究。

